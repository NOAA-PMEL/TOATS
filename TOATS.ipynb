{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best practices for assessing <u>T</u>rends of <u>O</u>cean <u>A</u>cidification <u>T</u>ime <u>S</u>eries (TOATS)\n",
    "\n",
    "Roman Battisti<sup>1,2</sup> and Adrienne J. Sutton<sup>2</sup>\n",
    "\n",
    "<sup>1</sup>Cooperative Institute for Climate, Ocean, and Ecosystem Studies, University of Washington, Seattle, WA, 98115\n",
    "\n",
    "<sup>2</sup>Pacific Marine Environmental Laboratory, NOAA, Seattle, Washington, USA\n",
    "\n",
    "\n",
    "\n",
    "A supplement to Sutton AJ, Battisti R, Carter B, Evans W, Newton J, Alin S, Bates NR, Cai W-J, Currie K, Feely RA, Sabine C, Tanhua T, Tilbrook B and Wanninkhof R (2022) Advancing best practices for assessing trends of ocean acidification time series. Front. Mar. Sci. 9:1045667. doi: 10.3389/fmars.2022.1045667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "# standard libraries\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "import re\n",
    "import requests\n",
    "import warnings\n",
    "\n",
    "# 3rd party libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from tabulate import tabulate\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# set size of figures\n",
    "%matplotlib widget\n",
    "plt.rcParams['figure.figsize'] = (8, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASSUMPTIONS\n",
    "***\n",
    "- Data collation and quality control are completed prior to loading the time series data. \n",
    "- Data are normally distributed.\n",
    "- All data are subject to the same biases and have equal precision.\n",
    "- If data gaps exist, they will not impact the calculations of climatological monthly or annual means.\n",
    "- Autocorrelation is present in ocean biogeochemical time series but accounted for in the following approaches for linear regression and trend detection time.\n",
    "- The user of this code has read the associated README.md file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD TIME SERIES DATA\n",
    "***\n",
    "Running the next cell will open dialogue boxes asking the user to enter the name of the .csv or .txt time series data file, the site name, and additional information about each carbon variable.  For more information on the required structure and formating of the data file, see associated README.md."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for reading tab- and comma-delimited files \n",
    "def separator_check(text):\n",
    "    for sep in [',', '\\t']:\n",
    "        if re.search(sep, text):\n",
    "            return sep\n",
    "    return None\n",
    "\n",
    "# functions to load data file to dataframe \n",
    "def load_file_to_pandas(file_name, comment_indicator=None): \n",
    "    with open(file_name, 'r') as f:\n",
    "        sep = None\n",
    "        for data in f:\n",
    "            sep = separator_check(data)\n",
    "            break\n",
    "    return pd.read_csv(file_name, sep=sep, engine='python', dtype={0: str})\n",
    "\n",
    "def trend_options(df_columns):\n",
    "    print('')\n",
    "    for i, col in enumerate(df_columns[1:]):\n",
    "        print('{}:\\t{}'.format(i + 1, col))\n",
    "    selection = int(input('Select the number associated with the parameter to process for trends: '))\n",
    "    print('{} selected...'.format(df_columns[selection]))\n",
    "    print('')\n",
    "    return df_columns[selection]\n",
    "\n",
    "class ExtensionException(Exception):\n",
    "    pass\n",
    "\n",
    "# UI for entry of source file and site name\n",
    "comment_indicator = None\n",
    "file_name = input(\"Input the data file name with extension: \")\n",
    "site_name = input(\"Input the site name: \")\n",
    "ts_df = load_file_to_pandas(file_name)\n",
    "\n",
    "print('\\nBeginning of the dataframe with the imported data:')\n",
    "datetime_col = ts_df.columns[0]\n",
    "variable_names = list(ts_df.columns[1:])\n",
    "var_sigfig_dict = {}\n",
    "var_unc_dict = {}\n",
    "var_unit_dict = OrderedDict()\n",
    "for var in variable_names:\n",
    "    var_sigfig_value = int(input(f\"Please provide the number of decimal places for {var}: \"))\n",
    "    var_uncertainty_value = float(input(f\"Please provide the uncertainty for {var}: \"))\n",
    "    var_units = input(f\"Please provide the units of {var}: \")\n",
    "    print(\"\\n\")\n",
    "    var_sigfig_dict[var] = var_sigfig_value\n",
    "    var_unc_dict[var] = var_uncertainty_value\n",
    "    var_unit_dict[var] = var_units\n",
    "\n",
    "ts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Date format test\n",
    "def build_formatted_string(string: str, char_requirements_dict: dict):\n",
    "    from collections import Counter\n",
    "    string = np.array(list(string.lower()))\n",
    "    _, idx = np.unique(string, return_index=True)\n",
    "    char_counter = Counter(string)\n",
    "    string = string[np.sort(idx)]\n",
    "    output = []\n",
    "    \n",
    "    # check for required characters\n",
    "    if 'y' in char_requirements_dict:\n",
    "        for c in char_requirements_dict.keys():\n",
    "            if c not in char_counter:\n",
    "                raise FormatError(f\"The character {c} is missing in your date format and is required.\")\n",
    "    elif 'h' in char_requirements_dict:\n",
    "        if 'h' not in char_counter:\n",
    "            raise FormatError(\"The character h is missing in your time format and is required\")\n",
    "    \n",
    "    for c in string:\n",
    "        # check that there are no meaningless additional characters\n",
    "        if c not in char_requirements_dict:\n",
    "            raise FormatError(f\"{c} is not a valid character for a datetime format or your datetime is ordered incorrectly.\")\n",
    "        # make sure number of characters is consistent with formatting constraints\n",
    "        if char_counter[c] not in char_requirements_dict[c]:\n",
    "            raise FormatError(f\"{c} must have {char_requirements_dict[c]} number of characters.\")\n",
    "        elif char_counter[c] == char_requirements_dict[c][0]:\n",
    "            output.append(c)\n",
    "        elif char_counter[c] == char_requirements_dict[c][1]:\n",
    "            output.append(c.upper())\n",
    "    return '%' + '%'.join(output)\n",
    "\n",
    "def convert_datetime_format_string(string: str):\n",
    "    date_requirements_dict = {'m': [2], 'd': [2], 'y': [2, 4]}\n",
    "    time_requirements_dict = {'h': [None, 2], 'm': [None, 2], 's': [None, 2]}\n",
    "    separated_string = string.split(' ')\n",
    "    if len(separated_string) > 2:\n",
    "        raise FormatError(\"There are too many inputs for a datetime string format. Make sure your datetime only has one space between the date and time.\")\n",
    "    output = []\n",
    "    for i in range(len(separated_string)):\n",
    "        # assume first part is date, second part is time\n",
    "        if i == 0:\n",
    "            output.append(build_formatted_string(separated_string[i], date_requirements_dict))\n",
    "        elif i == 1:\n",
    "            output.append(build_formatted_string(separated_string[i], time_requirements_dict))\n",
    "        else:\n",
    "            raise FormatError(\"There are too many spaces in your date/time format. There should be at most two, one for the date and one for the time.\")\n",
    "    return ' '.join(output)\n",
    "\n",
    "\n",
    "class FormatError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "dayfirst = 'n'\n",
    "dayformat = None\n",
    "\n",
    "try:  # if date is entirely numeric with no separators\n",
    "    date_test = np.array([t.split() for t in ts_df.iloc[:, 0]]).astype(int)\n",
    "    dayformat = input(\"What is the date format of your data (ex yyyymmdd, ddmmyyyy HHMMSS, etc)? \").upper()\n",
    "    dayformat = convert_datetime_format_string(dayformat)\n",
    "    \n",
    "except ValueError:\n",
    "    day_test_df = ts_df.iloc[:, 0].str.split('[,\\s/-]+|T', expand=True)\n",
    "    if len(day_test_df.columns) > 2:  # if datetime can be separated. Otherwise, try to let pandas handle it.\n",
    "        int_columns = []\n",
    "        for col in day_test_df.columns[:3]:  # test whether each column in split date can be converted to int\n",
    "            try:\n",
    "                day_test_df = day_test_df.astype({col: int})\n",
    "                int_columns.append(col)\n",
    "            except ValueError:  # assume an error results from the month in string form\n",
    "                pass\n",
    "        day_test_max = day_test_df.iloc[:, int_columns].aggregate(max)\n",
    "        daypos = [col for col in day_test_max.index if day_test_max[col] > 12 and day_test_max[col] < 32]\n",
    "        if daypos and int_columns[daypos[0]] == 0:\n",
    "            dayfirst = 'y'\n",
    "        elif not dayfirst:\n",
    "            dayfirst = input(\"Are days first in the datetimes being imported (y or n)? \")\n",
    "except FormatError as e:\n",
    "    print(\"The following exception was raised: \", e)\n",
    "    print(\"Please rerun the cell with a properly formatted date format or reformat your datetimes in your file to an acceptable format.\")\n",
    "\n",
    "dp_str_dict = {k: '%.' + str(var_sigfig_dict[k]) + 'f' for k in var_sigfig_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def decimal_month(years, months, days):\n",
    "    \"\"\"Compute the decimal month (ex. March 15 would be 3.48 or 3 + 15/31). Account for number of days in February using year.\"\"\"\n",
    "    days_in_month = {1: 31, 3: 31, 4: 30, 5: 31, 6: 30, 7: 31, 8: 31, 9: 30, 10: 31, 11: 30, 12: 31}\n",
    "    feb_days = {y: 29 if y%400 == 0 or (y%4 == 0 and not y%100==0) else 28 for y in np.unique(years)}\n",
    "    output = []\n",
    "    for y, m, d in zip(years, months, days):\n",
    "        if m == 2:\n",
    "            output.append(m + (d - 1) / feb_days[y])\n",
    "        else:\n",
    "            output.append(m + (d - 1) / days_in_month[m])\n",
    "    return output\n",
    "\n",
    "# make datetime the index and calculate decimal year\n",
    "if dayformat:\n",
    "    ts_df[datetime_col] = pd.to_datetime(ts_df[datetime_col], format=dayformat)\n",
    "elif dayfirst == 'y':\n",
    "    ts_df[datetime_col] = pd.to_datetime(ts_df[datetime_col],dayfirst=True)\n",
    "else:\n",
    "    ts_df[datetime_col] = pd.to_datetime(ts_df[datetime_col])\n",
    "\n",
    "ts_df.index = ts_df[datetime_col]\n",
    "ts_df['year'] = pd.DatetimeIndex(ts_df[datetime_col]).year\n",
    "ts_df['month'] = pd.DatetimeIndex(ts_df[datetime_col]).month\n",
    "ts_df['day'] = pd.DatetimeIndex(ts_df[datetime_col]).day\n",
    "ts_df['decimal_month'] = decimal_month(ts_df['year'], ts_df['month'], ts_df['day'])\n",
    "ts_df['decimal_year'] = ts_df['year'] + (ts_df['decimal_month'] - 1) / 12\n",
    "\n",
    "# create dictionary of dataframes only containing one variable each\n",
    "additional_columns = ['year', 'month', 'day', 'decimal_month', 'decimal_year']\n",
    "ts_df_dict = {var: deepcopy(ts_df[[var] + additional_columns]) for var in variable_names}\n",
    "\n",
    "# remove NaNs\n",
    "for k in ts_df_dict.keys():\n",
    "    ts_df_dict[k].dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) ASSESS DATA GAPS\n",
    "***\n",
    "Assess plot and monthly statistics to determine whether obervations are sufficient to constrain climatological monthly means and the annual climatological mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calculate and display monthly and annual statistics\n",
    "ts_stats = {}\n",
    "\n",
    "for k, v in ts_df_dict.items():\n",
    "    ts_monthly_stats = round(v.groupby('month').agg({k: ['mean', 'std', 'count']}), var_sigfig_dict[k])\n",
    "    ts_annual_stats = round(v.groupby('year').agg({k: ['mean', 'std', 'count']}), var_sigfig_dict[k])\n",
    "    ts_stats[k] = {'monthly': ts_monthly_stats, 'annual': ts_annual_stats}\n",
    "\n",
    "    # plot monthly means and histogram of monthly measurements\n",
    "    plt.figure()\n",
    "    plt.errorbar(ts_monthly_stats.index, ts_monthly_stats[k]['mean'], \n",
    "                    ts_monthly_stats[k]['std'], marker= 'o', elinewidth=1, \n",
    "                    linewidth=2)\n",
    "    plt.title(f\"{k} monthly means and std\")\n",
    "    plt.xlabel('Month')\n",
    "    plt.xticks(np.arange(1, 13, step=1))\n",
    "    plt.ylabel(f\"seawater {k} ({var_unit_dict[k]})\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(ts_df_dict[k]['month'], bins=np.arange(14)-0.5, edgecolor='black', rwidth=0.8)\n",
    "    plt.title(f\"{k} monthly measurement distribution\")\n",
    "    plt.xlabel(\"month\") \n",
    "    plt.ylabel(\"# of measurements\") \n",
    "    plt.xticks([1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "    plt.xlim([0.5,12.5])\n",
    "    plt.show()\n",
    "    \n",
    "print('\\nBefore continuing, the user should confirm that monthly measurement distributions are sufficient to constrain climatological monthly means and the annual climatological mean.','\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) REMOVE PERIODIC (SEASONAL) SIGNAL\n",
    "***\n",
    "The following steps characterize the seasonal signal and remove that noise from the time series of monthly means, creating a time series of de-seasoned monthly means used in the trend analysis:\n",
    "- Temporarily remove the overall linear trend by applying a simple linear regression and removing the slope from the original data set. \n",
    "- Using this de-trended time series, calculate climatological monthly means and determine the climatological annual mean (mean of the climatological monthly means).\n",
    "- Determine the monthly adjustments by subtracting the climatological annual mean from the climatological monthly means.  \n",
    "- Subtract the adjustment value for each month from the time series of monthly means, which was not de-trended. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_trends = {}\n",
    "\n",
    "for k, v in ts_df_dict.items():\n",
    "    # fit linear model\n",
    "    decimal_year = np.reshape(v['decimal_year'].to_numpy(), (-1,1))\n",
    "    decimal_year = sm.add_constant(decimal_year)\n",
    "    ts_variable = v[k].to_numpy()\n",
    "    ts_variable = np.reshape(ts_variable, (-1,1))\n",
    "    model = sm.OLS(ts_variable, decimal_year).fit(cov_type='HAC', cov_kwds={'maxlags':1})\n",
    "    \n",
    "    # calculate trend\n",
    "    trend_to_remove = model.predict(decimal_year)\n",
    "\n",
    "    # temporarily remove trend\n",
    "    detrended = [ts_variable[i]-trend_to_remove[i] for i in range(0, len(decimal_year))]\n",
    "\n",
    "    # extract slope and error values from OLS results and print results\n",
    "    trend_to_remove_slope = dp_str_dict[k] % model.params[1]\n",
    "    trend_to_remove_slope_error = dp_str_dict[k] % model.bse[1]\n",
    "    var_trends[k] = {'model': model, 'detrended': detrended, 'slope_str': trend_to_remove_slope, 'slope_error_str': trend_to_remove_slope_error}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new dataframe with de-trended values\n",
    "for k, v in var_trends.items():\n",
    "    detrended = np.round(v['detrended'], var_sigfig_dict[k])\n",
    "    detrended_df = pd.DataFrame(data=detrended, index=ts_df_dict[k].index, columns=['detrended_variable'])\n",
    "    detrended_df['month'] = detrended_df.index.month\n",
    "    detrended_df['year'] = detrended_df.index.year\n",
    "    v['detrended'] = detrended_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# climatological monthly mean of de-trended values\n",
    "for k, v in var_trends.items():\n",
    "    ts_month = v['detrended'].groupby('month')\n",
    "    climatological_df = round(ts_month.agg({'detrended_variable': ['mean']}), var_sigfig_dict[k])\n",
    "\n",
    "    # climatological annual mean of de-trended values\n",
    "    annual_mean = np.mean(climatological_df['detrended_variable']['mean'])\n",
    "\n",
    "    # monthly seasonal adjustment \n",
    "    climatological_df['monthly_adj'] = np.round(climatological_df['detrended_variable']['mean'].values - annual_mean, var_sigfig_dict[k])\n",
    "\n",
    "    # seasonal amplitude and interannual variability for display in summary report\n",
    "    season_max = climatological_df.detrended_variable['mean'].max()\n",
    "    season_min = climatological_df.detrended_variable['mean'].min()\n",
    "    seasonal_amplitude = round(season_max - season_min, var_sigfig_dict[k])\n",
    "\n",
    "    annual_means = v['detrended'].groupby('year') \n",
    "    annual_means_df = annual_means.agg({'detrended_variable':['mean']})\n",
    "    IAV = round(np.mean(abs(annual_means_df.detrended_variable['mean'])), var_sigfig_dict[k])\n",
    "    v['climatological'] = climatological_df\n",
    "    v['seasonal_amplitude'] = seasonal_amplitude\n",
    "    v['annual_means'] = annual_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply monthly adjustment to monthly means of the original time series, which was not de-trended\n",
    "for k, v in var_trends.items():\n",
    "    ts_year_month = ts_df_dict[k].groupby(['year','month'])\n",
    "\n",
    "    ts_mean = round(ts_year_month.agg({k: ['mean']}), var_sigfig_dict[k])\n",
    "    ts_mean[k,'datetime_mean'] = [datetime(i[0],i[1],15,0,0,0) for i in ts_mean.index]\n",
    "\n",
    "    adj_mean = []\n",
    "    for i in ts_mean.index:\n",
    "        temp = ts_mean[k]['mean'][i] - v['climatological']['monthly_adj'][i[1]]\n",
    "        adj_mean.append(temp)\n",
    "\n",
    "    # create time series of de-seasoned monthly means (variable name = adj_mean)\n",
    "    ts_mean[k, 'adj_mean'] = adj_mean\n",
    "    v['ts_mean'] = ts_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) ASSESS LINEAR FIT TO THE DATA WITH THE PERIODIC SIGNAL REMOVED\n",
    "***\n",
    "Determines the linear trend of de-seasoned monthly means and regression statistics. The Weighted Least Squares linear regression model from the statsmodels Python module (www.statsmodels.org/dev/regression.html) is used with Newey-West standard errors to account for heteroskedasticity and autocorrelation. For a description of all elements of the output, refer to the open-source statsmodels documentation (www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLSResults.html)\n",
    "\n",
    "Newey, Whitney K; West, Kenneth D (1987). \"A Simple, Positive Semi-definite, Heteroskedasticity and Autocorrelation Consistent Covariance Matrix\". Econometrica 55 (3): 703–708. doi:10.2307/1913610"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create decimal year\n",
    "for k, v in var_trends.items():\n",
    "    ts_mean = v['ts_mean']\n",
    "    ts_mean[k,'year'] = pd.DatetimeIndex(ts_mean[k]['datetime_mean']).year\n",
    "    ts_mean[k,'month'] = pd.DatetimeIndex(ts_mean[k]['datetime_mean']).month\n",
    "    ts_mean[k,'day'] = pd.DatetimeIndex(ts_mean[k]['datetime_mean']).day\n",
    "    ts_mean[k,'decimal_month'] = decimal_month(ts_mean[k]['year'], ts_mean[k]['month'], ts_mean[k]['day'])\n",
    "    ts_mean[k, 'decimal_year'] = ts_mean[k]['year'] + (ts_mean[k]['decimal_month'] - 1) / 12\n",
    "    v['ts_mean'] = ts_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create series of dates adjusted to start at 0 for use in the regression model \n",
    "# this prevents the y-intercept value from being highly sensitive to input dates\n",
    "wls_model_dict = {}\n",
    "for k, v in var_trends.items():\n",
    "    ts_mean = v['ts_mean']\n",
    "    decimal_year_deseasoned = np.reshape(ts_mean[k]['decimal_year'].values, (-1, 1))\n",
    "    min_year = np.amin(decimal_year_deseasoned)\n",
    "    decimal_year_zero = decimal_year_deseasoned-min_year\n",
    "    decimal_year_zero = sm.add_constant(decimal_year_zero)\n",
    "    ts_variable_deseasoned = ts_mean[k]['adj_mean'].values\n",
    "    ts_variable_deseasoned = np.reshape(ts_variable_deseasoned,(-1, 1))\n",
    "\n",
    "    # Weights are based on user input uncertainty\n",
    "    weights = var_unc_dict[k] * np.ones(len(ts_variable_deseasoned))\n",
    "\n",
    "    # Statsmodel's WLS() requires that the weights are proportional to the inverse of the error variance\n",
    "    weights = 1.0 / (weights ** 2)\n",
    "\n",
    "    # fit linear model\n",
    "    weights = var_unc_dict[k]  # uncertainties\n",
    "    model = sm.WLS(ts_variable_deseasoned,decimal_year_zero, weights).fit(cov_type='HAC',cov_kwds={'maxlags':1})\n",
    "    wls_model_dict[k] = {'model': model, 'decimal_year_zero': decimal_year_zero, 'ts_variable_deseasoned': ts_variable_deseasoned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calculate and plot trend \n",
    "for k, v in wls_model_dict.items():\n",
    "    model = v['model']\n",
    "    trend = model.predict(v['decimal_year_zero'])\n",
    "\n",
    "    # extract slope and error values from WLS results and print results\n",
    "    slope_str = dp_str_dict[k]\n",
    "    slope = slope_str % model.params[1]\n",
    "    slope_error = slope_str % model.bse[1]\n",
    "    wls_model_dict[k]['trend'] = trend\n",
    "    wls_model_dict[k]['slope_str'] = slope\n",
    "    wls_model_dict[k]['slope_err_str'] = slope_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) ESTIMATE TREND DETECTION TIME\n",
    "***\n",
    "This section uses the trend detection methods of Weatherhead et al. 1998 to estimate trend detection time.\n",
    "\n",
    "Weatherhead, E. C., Reinsel, G. C., Tiao, G. C., Meng, X.-L., Choi, D., Cheang, W.-K., et al. (1998). Factors affecting the detection of trends: Statistical considerations and applications to environmental data. Journal of Geophysical Research: Atmospheres, 103(D14), 17149-17161. http://dx.doi.org/10.1029/98JD00995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TDTi_dict = {}  # time of detection\n",
    "# autocorrelation at lag 1 of the time series noise\n",
    "for k, v in wls_model_dict.items():\n",
    "    ts_variable_deseasoned = v['ts_variable_deseasoned']\n",
    "    decimal_year_zero = v['decimal_year_zero']\n",
    "    autocorr = sm.tsa.stattools.acf(ts_variable_deseasoned,fft=False,nlags=1)[1:]\n",
    "    ts_mean = var_trends[k]['ts_mean']\n",
    "\n",
    "    # standard deviation of detrended monthly anomalies\n",
    "    model = v['model']\n",
    "    trend_to_remove_TDT = model.predict(decimal_year_zero)\n",
    "    detrended_TDT = [ts_variable_deseasoned[i]-trend_to_remove_TDT[i] for i in range(0, len(ts_mean[k]['datetime_mean']))]\n",
    "    std_dev = np.std(detrended_TDT)\n",
    "\n",
    "    # time of detection \n",
    "    TDTi = np.round((((3.3*std_dev)/(abs(model.params[1:])))*(np.sqrt(((1+autocorr)/(1-autocorr)))))**(2/3), 1)\n",
    "    ts_length = round(np.max(decimal_year_zero[:, 1]), 1)\n",
    "\n",
    "    # uncertainties of time of detection due to unknown variance and autocorrelation\n",
    "    uncert_factor = (4/(3*np.sqrt(len(ts_variable_deseasoned))))*(np.sqrt(((1+autocorr)/(1-autocorr))))\n",
    "    upper_conf_intervali = TDTi * math.exp(uncert_factor)\n",
    "    lower_conf_intervali = TDTi * math.exp(-uncert_factor)\n",
    "    uncert_TDTi = np.round(((upper_conf_intervali-TDTi)+(TDTi-lower_conf_intervali))/2,1)\n",
    "\n",
    "    dp_str = dp_str_dict[k]\n",
    "    TDT = dp_str % TDTi[0]\n",
    "    uncert_TDT = dp_str % uncert_TDTi[0]\n",
    "    upper_conf_interval = dp_str % upper_conf_intervali[0]\n",
    "    lower_conf_interval = dp_str % lower_conf_intervali[0]\n",
    "    \n",
    "    TDTi_dict[k] = {'TDTi': TDTi, 'ts_length': ts_length, 'TDT': TDT, 'uncert_TDT': uncert_TDT, 'upper_conf_interval': upper_conf_interval, 'lower_conf_interval': lower_conf_interval}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary report:\n",
    "### 5) CONSIDER UNCERTAINTY IN THE MEASUREMENTS AND REPORTED TRENDS\n",
    "### 6) PRESENT RESULTS IN THE CONTEXT OF NATURAL VARIABILITY AND UNCERTAINTY\n",
    "\n",
    "After running the following cell, the user will be prompted to enter one of the variable names. After the variable is entered, running the next cell will generate summary statistics for that variable. The time series of de-seasoned monthly means for that variable will be exported to a .csv file saved to the same location as this jupyter notebook. These two cells can be rerun, selecting different variables to summarize without needing to rerun the entire notebook.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in var_unit_dict.keys():\n",
    "    print(k)\n",
    "print(\"\\n\")\n",
    "\n",
    "param_to_summerize = input('Please select from the available parameters to see a summary: ')\n",
    "\n",
    "while True:\n",
    "    test = wls_model_dict.get(param_to_summerize, False)\n",
    "    if not test:\n",
    "        param_to_summerize = input(\"The parameter you've selected doesn't exist, please select from the available parameters: \")\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# organize parameters\n",
    "ts_df = ts_df_dict[param_to_summerize]\n",
    "dp = var_sigfig_dict[param_to_summerize]\n",
    "units = var_unit_dict[param_to_summerize]\n",
    "model = wls_model_dict[param_to_summerize]['model']\n",
    "\n",
    "ts_annual_stats = ts_stats[param_to_summerize]['annual']\n",
    "ts_monthly_stats = ts_stats[param_to_summerize]['monthly']\n",
    "\n",
    "slope = wls_model_dict[param_to_summerize]['slope_str']\n",
    "slope_error = wls_model_dict[param_to_summerize]['slope_err_str']\n",
    "\n",
    "ts_mean = var_trends[param_to_summerize]['ts_mean']\n",
    "ts_variable_deseasoned = wls_model_dict[param_to_summerize]['ts_variable_deseasoned']\n",
    "trend = wls_model_dict[param_to_summerize]['trend']\n",
    "\n",
    "td = TDTi_dict[param_to_summerize]\n",
    "TDTi = td['TDTi']\n",
    "ts_length = td['ts_length']\n",
    "TDT = td['TDT']\n",
    "uncert_TDT = td['uncert_TDT']\n",
    "upper_conf_interval = td['upper_conf_interval']\n",
    "lower_conf_interval = td['lower_conf_interval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# summary of OLS Regression Results\n",
    "print('---Summary of OLS Regression Results---','\\n')\n",
    "\n",
    "# create table header\n",
    "head = [\"Statistic\", \"Value\", \"Result\"]\n",
    "\n",
    "# create CI and variance values\n",
    "CI = model.conf_int()\n",
    "CI_values = np.round(CI[1],dp)\n",
    "CI_low = CI_values[0] \n",
    "CI_high = CI_values[1] \n",
    "adj_r2 = round(model.rsquared_adj,2)\n",
    "adj_r2_percent = int(adj_r2 * 100)\n",
    "\n",
    "\n",
    "if model.pvalues[1:] >= 0.05: # model.pvalues[:1] >= 0.05 and\n",
    "    statsdata = [[\"P > |z|\", \"> 0.05\", \"The slope coefficient is not significant\"], \n",
    "      [\"Adjusted r2\", adj_r2, \"The model describes {}% of the variation in {} over time\".format(adj_r2_percent, param_to_summerize)], \n",
    "      [\"Standard error\", slope_error, \"The estimated {} trend is {} ± {} {} per year\".format(param_to_summerize, slope, slope_error, units)], \n",
    "      [\"[0.025 and 0.975]\", \"{} to {}\".format(CI_low, CI_high), \"The 95% CI for the trend is {} to {} {} per year\".format(CI_low, CI_high, units)]]\n",
    "\n",
    "    # display table\n",
    "    print(tabulate(statsdata, headers=head, tablefmt=\"rst\"))\n",
    "\n",
    "    print('The p-value for how likely the slope coefficient is measured through the linear model by chance is > 0.05, suggesting the coefficient is not statistically significant.', '\\n')\n",
    "    print(\"High slope error and low adjusted r-squared should also suggest lack of significance in the trend. In this case slope error is {} uatm per year compared to a slope of {} uatm per year and adjusted r-squared is {}\".format(slope_error, slope, round(model.rsquared_adj,dp)),'\\n')\n",
    "\n",
    "else:\n",
    "    statsdata = [[\"P > |z|\", \"< 0.05\", \"The slope coefficient is significant\"], \n",
    "      [\"Adjusted r2\", adj_r2, \"The model describes {}% of the variation in {} over time\".format(adj_r2_percent, param_to_summerize)], \n",
    "      [\"Standard error\", slope_error, \"The estimated {} trend is {} ± {} {} per year\".format(param_to_summerize, slope, slope_error, units)], \n",
    "      [\"[0.025 and 0.975]\", \"{} to {}\".format(CI_low, CI_high), \"The 95% CI for the trend is {} to {} {} per year\".format(CI_low, CI_high, units)]]\n",
    "\n",
    "    # display table\n",
    "    print(tabulate(statsdata, headers=head, tablefmt=\"rst\"))\n",
    "\n",
    "    print('The p-value for how likely the slope coefficient is measured through the linear model by chance is < 0.05, suggesting the coefficient is statistically significant.', '\\n')\n",
    "    print(\"Low slope error and high adjusted r-squared should also accompany a low p-value if the trend is statistically significant. In this case slope error is {} {} per year compared to a slope of {} {} per year and adjusted r-squared is {}.\".format(slope_error, units, slope, units, round(model.rsquared_adj,dp)),'\\n')\n",
    "\n",
    "\n",
    "# summary of trend detection results\n",
    "print('---Summary of Trend Detection Results---','\\n')\n",
    "print(\"The number of years to detect a trend of {} {} per year at {} is approximately {} ± {} with a confidence interval of {} to {} years.\".format(slope,units,site_name,TDT,uncert_TDT,lower_conf_interval,upper_conf_interval),'\\n')\n",
    "if ts_length < TDTi:\n",
    "    print(\"The {} time series length of {} years may not be long enough to detect a statistically-significant trend.\".format(site_name,ts_length),'\\n')\n",
    "else:\n",
    "    print(\"The {} time series length of {} years may be long enough to detect a statistically-significant trend.\".format(site_name,ts_length),'\\n')\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(ts_df.index, ts_df[param_to_summerize], marker='.', label='observations')\n",
    "plt.plot(ts_mean[param_to_summerize]['datetime_mean'], ts_variable_deseasoned, c='r', marker= 's', markersize=4, linewidth=0, label='monthly anomalies')\n",
    "plt.plot(ts_mean[param_to_summerize]['datetime_mean'], ts_mean[param_to_summerize]['mean'], c='k', marker= 'o', markersize=4, linewidth=0, label='monthly means')\n",
    "plt.plot(ts_mean[param_to_summerize]['datetime_mean'], trend, c='r', linewidth=2, label='trend')\n",
    "plt.title(\"{} time series\".format(site_name)) \n",
    "plt.ylabel(\"seawater {} ({})\".format(param_to_summerize, units)) \n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# assumptions\n",
    "print('---Assumptions and considerations---','\\n')\n",
    "print('These trend results are only valid if the data are normally distributed and all data are subject to the same biases and have equal precision.','\\n')\n",
    "print(\"Characterizing and removing periodic signal(s) in time series prior to estimating trends reduces noise in the data set, thereby reducing uncertainty in the resulting trend. The method used here removes the seasonal signal, which is a seasonal amplitude of {} {} for this time series.  Daily, tidal, interannual, or decadal signals could also be characterized and removed to further reduce trend uncertainty.\".format(seasonal_amplitude,units),'\\n')\n",
    "print(\"The impact of interannual or decadal variability on trends could also be assessed by calculating trends over different time periods within the data set. For example, to interrogate how different phases of the El Niño Southern Oscillation (ENSO) impact long-term change, the data set could be separated into El Niño, La Niña, and neutral time periods and trends assessed separately for the different ENSO phases.  Interannual variability of {} for this time series is {} {}.\".format(param_to_summerize, IAV, units),'\\n')\n",
    "print(\"The seasonal amplitude and interannual variability estimates are based on the data below.  If data are nonuniform across months and years, these estimates may not be valid.\")\n",
    "      \n",
    "# plot monthly means\n",
    "fig, ax = plt.subplots()\n",
    "ax.errorbar(ts_monthly_stats.index, ts_monthly_stats[param_to_summerize]['mean'], \n",
    "                ts_monthly_stats[param_to_summerize]['std'], marker= 'o', elinewidth=1, \n",
    "                linewidth=2)\n",
    "ax.set_title(\"{} monthly means and std\".format(site_name)) \n",
    "ax.set_xlabel('Month')\n",
    "ax.set_xticks(np.arange(1, 13, step=1))\n",
    "ax.set_ylabel(\"seawater {} ({})\".format(param_to_summerize, units)) \n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(ts_df['month'], bins=np.arange(14)-0.5, edgecolor='black', rwidth=0.8)\n",
    "plt.title(\"{} monthly measurement distribution\".format(site_name)) \n",
    "plt.xlabel(\"month\") \n",
    "plt.ylabel(\"# of measurements\") \n",
    "plt.xticks([1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "plt.xlim([0.5,12.5])\n",
    "plt.show()\n",
    "\n",
    "display(ts_monthly_stats)\n",
    "\n",
    "# plot annual means\n",
    "fig, ax = plt.subplots()\n",
    "ax.errorbar(ts_annual_stats.index, ts_annual_stats[param_to_summerize]['mean'], \n",
    "                ts_annual_stats[param_to_summerize]['std'], marker= 'o', elinewidth=1, \n",
    "                linewidth=2)\n",
    "ax.set_title(\"{} annual means and std\".format(site_name)) \n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel(\"seawater {} ({})\".format(param_to_summerize, units)) \n",
    "plt.show()\n",
    "\n",
    "maxyear = max(ts_df['year'])\n",
    "minyear = min(ts_df['year'])\n",
    "nyears = maxyear-minyear\n",
    "allyears = np.append([np.unique(ts_df['year'])],[maxyear+1])\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(ts_df['year'], bins=allyears-0.5, edgecolor='black', rwidth=0.8)\n",
    "plt.title(\"{} annual measurement distribution\".format(site_name)) \n",
    "plt.xlabel(\"year\") \n",
    "plt.ylabel(\"# of measurements\") \n",
    "plt.show()\n",
    "\n",
    "display(ts_annual_stats)\n",
    "\n",
    "# export time series of de-seasoned monthly means \n",
    "month_year = np.reshape(ts_mean[param_to_summerize]['datetime_mean'].values,\n",
    "               (len(ts_mean[param_to_summerize]['datetime_mean']),1))\n",
    "deseasoned_df = pd.DataFrame(data = [month_year[:,0],np.round(ts_variable_deseasoned[:,0], dp)]).T\n",
    "deseasoned_df.columns = [\"date\", \"deseasoned_monthly_mean_{}\".format(param_to_summerize)]\n",
    "deseasoned_df.to_csv(f'{site_name}_{param_to_summerize}_deseasoned_monthly_means.csv', index = False, header = True)\n",
    "print('\\n---De-seasoned data export---','\\n')\n",
    "print(\"The time series of de-seasoned {} monthly means has be exported to a file called deseasoned_monthly_means.csv saved to the same location as this jupyter notebook.\".format(param_to_summerize),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
